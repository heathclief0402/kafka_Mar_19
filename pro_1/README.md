# Kafka-MySQL Data Pipeline

This project creates a **Kafka-based data pipeline** where employee salary data is streamed, aggregated per department, and stored in a **MySQL database** inside a Docker container.

## **ğŸ“Œ Project Overview**
1. **Producer**: Reads employee salary data from a CSV file and sends it to a Kafka topic.
2. **Consumer**: Listens for messages, aggregates salaries by department, and stores the total in MySQL.
3. **Database (MySQL)**: Stores **total salary per department**.

---

## **ğŸš€ Setup Instructions**
### **1ï¸âƒ£ Prerequisites**
Ensure you have:
- **Docker & Docker Compose** installed ([Download Here](https://www.docker.com/get-started))
- **Python 3.8+** installed ([Download Here](https://www.python.org/downloads/))
- **Kafka & Zookeeper** set up via Docker
- **Kafka-Python** & **MySQL Connector** installed

Install dependencies:
```sh
pip install kafka-python mysql-connector-python pandas
```

---

## **ğŸ› ï¸ Setup & Run the Project**
### **2ï¸âƒ£ Start Docker Services**
Run:
```sh
docker-compose up -d
```
This starts **Kafka, Zookeeper, and MySQL** inside Docker.

Check running containers:
```sh
docker ps
```

---

### **3ï¸âƒ£ Create & Verify MySQL Database**
Connect to MySQL inside Docker:
```sh
docker exec -it pro_1-mysql mysql -u user -p
```
(Enter password: `password`)

Create the **salaries database** (if not already created):
```sql
CREATE DATABASE salaries;
USE salaries;
```

---

### **4ï¸âƒ£ Run the Producer**
The **producer reads from `Employee_Salaries.csv` and sends messages to Kafka**.
```sh
python producer.py
```

---

### **5ï¸âƒ£ Run the Consumer**
The **consumer listens to Kafka, aggregates salaries per department, and updates MySQL**.
```sh
python consumer.py
```

---

### **6ï¸âƒ£ Verify Stored Data in MySQL**
Connect to MySQL:
```sh
docker exec -it pro_1-mysql mysql -u user -p salaries
```
Check department-wise total salaries:
```sql
SELECT * FROM employee_salaries;
```

âœ… **Now, your pipeline is fully functional!**

---

## **ğŸ“ Project Structure**
```
ğŸ“‚ kafka_mysql_pipeline
 â”œâ”€â”€ ğŸ“œ docker-compose.yml   # Defines Kafka, Zookeeper, MySQL
 â”œâ”€â”€ ğŸ“œ producer.py          # Sends salary data to Kafka
 â”œâ”€â”€ ğŸ“œ consumer.py          # Reads from Kafka & updates MySQL
 â”œâ”€â”€ ğŸ“œ Employee_Salaries.csv # Sample salary data
 â”œâ”€â”€ ğŸ“œ README.md            # Project documentation
```

---

## **âš¡ Troubleshooting**
### âŒ **Port Already in Use (3306)**
**Solution**: Change MySQL port in `docker-compose.yml`:
```yaml
ports:
  - "3307:3306"  # Use 3307 instead of 3306 on the host
```
Then restart:
```sh
docker-compose down
docker-compose up -d
```

### âŒ **Kafka Consumer is Not Receiving Messages**
Check if Kafka is running:
```sh
docker logs pro_1-kafka
```
Check available topics:
```sh
docker exec -it pro_1-kafka kafka-topics.sh --list --bootstrap-server localhost:9092
```

### âŒ **Failed to Connect to MySQL**
If `consumer.py` fails to connect:
- Ensure MySQL is running (`docker ps`)
- Use `DB_HOST = "localhost"` if running **outside Docker**
- Use `DB_HOST = "pro_1-mysql"` if running **inside Docker**

---

## **ğŸ¯ Future Improvements**
âœ… **Implement Kafka Dead Letter Queue (DLQ) for error handling**  
âœ… **Create a dashboard using Power BI or Tableau**  
âœ… **Use Apache Airflow to schedule and monitor pipeline execution**  

ğŸš€ **Congratulations! Youâ€™ve built a scalable Kafka-MySQL pipeline!** ğŸš€
